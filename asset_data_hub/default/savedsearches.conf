[Asset List Update Old-Clean]
cron_schedule = 0 20 * * *
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
description = Clean asset list old
enableSched = 1
search = | inputlookup asset_list_old.csv | eval date=strptime(date,"%F") | where date >= now()-(60*60*24*365) AND date < now()-(60*60*24*90) |eval date=strftime(date,"%F") | outputlookup asset_list_old.csv

[Asset List Update new]
cron_schedule = 30 4 * * *
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
enableSched = 1
search = | inputlookup asset_list.csv | eval date=strptime(date,"%F") | where date >= now()-(60*60*24*90) OR msl=1 | eval date=strftime(date,"%F") | outputlookup asset_list.csv

[Asset List Update Final]
cron_schedule = 0 5 * * *
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 15
search = | inputlookup append=true asset_list.csv | `os_part` | `asset_list_ou` | outputlookup asset_list.csv

[AD List Old]
cron_schedule = 15 20 * * *
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
description = Saves host Information for hosts no longer in AD.
dispatch.earliest_time = -24h@d
enableSched = 1
search = | inputlookup ad_list.csv | eval ad_date=strptime(ad_date, "%F") | eval ad_print=if(ad_print="1","1","0") | where ad_date <= now()-(60*60*24*2) | eval ad_date=strftime(ad_date, "%F") | outputlookup ad_list_old.csv

[Asset List Update old]
cron_schedule = 30 20 * * *
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = | inputlookup asset_list.csv | eval date=strptime(date,"%F") | where date >= now()-(60*60*24*91) AND date <= now()-(60*60*24*90) OR msl=1 |eval date=strftime(date,"%F") |   inputlookup append=true asset_list_old.csv | eval date=strptime(date,"%F") | eval date=strftime(date,"%F") | outputlookup asset_list_old.csv

[Asset List Update Legacy]
cron_schedule = 45 20 * * *
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
description = Everything over 360 days old
enableSched = 1
search = | inputlookup asset_list_old.csv | eval date=strptime(date,"%F") | where date >= now()-(60*60*24*364) AND date <= now()-(60*60*24*365) OR msl=1 |eval date=strftime(date,"%F") |   inputlookup append=true asset_list_legacy.csv | eval date=strptime(date,"%F") | eval date=strftime(date,"%F") | outputlookup asset_list_legacy.csv

[Patches_available]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 35 3 * * *
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = index=tanium sourcetype="tanium:connect:syslog" Question_Name="Splunk-Available-Patches" | eval checkin=strftime(_time,"%F") | rex field=Date "^(?<year>\d{4})\-(?<month>\d+)"  | eval patchdate='year'."-".'month' | rename host as name | rename Operating_System as os, Computer_Name as host, Title as patch, Severity as severity, KB_Article as kb | rex field=os "^(?<os>\S+\d+)" | rex field=host "^(?<host>[\w\-\d]*)(?:\.(?<domain>[^\s]+)|\.|$)" | eval os=lower(os), host=lower(host), domain=lower(domain), checkin=lower(checkin), patch=lower(patch), severity=lower(severity), status=lower(kb) | stats first(checkin) as checkin, values(os) as os, values(domain) as domain, values(kb) as kb by host patchdate severity patch | inputlookup append=true available_patches.csv | outputlookup available_patches.csv

[Patches_combined]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 4 * * *
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = | inputlookup append=true installed_patches.csv | lookup asset_list.csv host OUTPUT tanium_uptime sccm_patchcycle sccm_patchwindow os_class msl_agency | outputlookup installed_patches2.csv

[Patches_complete]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 15 4 * * *
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = | inputlookup installed_patches2.csv  | fillnull value="n/a" sccm_patchcycle sccm_patchwindow | rex field=sccm_patchcycle max_match=0 "(?<sccm_cycle>no reboot|reboot|pilot reboot|available)" | rex field=sccm_patchwindow max_match=0 "(?<sccm_phase>\S{3} thurs)" | table host domain os os_class msl_agency checkin installdate installpatch sccm* tanium_uptime | replace "no reboot" with "none" in sccm_cycle | eval reboot_yes=case(sccm_cycle LIKE "reboot", "yes") | eval reboot_no=case(sccm_cycle LIKE "none", "yes") | eval reboot_manual=case(sccm_cycle LIKE "available", "yes") | eval phase_manual=case(sccm_patchwindow LIKE "%na manual%","yes") | eval phase_na=case(sccm_patchwindow LIKE "%servers not%", "yes") | eval phase_0=case(sccm_phase LIKE "%2nd%", "yes") | eval phase_1=case(sccm_phase LIKE "%3rd%", "yes")  | eval phase_2=case(sccm_phase LIKE "%4th%", "yes")  | eval phase_3=case(sccm_phase LIKE "%1st%", "yes") | fillnull value="no" phase_0 phase_1 phase_2 phase_3 phase_manual phase_na reboot_manual reboot_no reboot_yes | fields - sccm_cycle sccm_phase | outputlookup patchphase.csv

[Patches_installed]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 45 3 * * *
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = index=tanium sourcetype="tanium:connect:syslog" Question_Name="Splunk-JSP-Patch-History" | eval checkin=strftime(_time,"%F") | eval installdate=strptime(Date, "%m/%d/%Y") | eval installdate=strftime(installdate, "%F") | rename Computer_Name as host, Title as installpatch, Operation as status, Operating_System as os | rex field=os "^(?<os>\S+\d+)" | rex field=host "^(?<host>[\w\-\d]*)(?:\.(?<domain>[^\s]+)|\.|$)"  | eval os=lower(os), host=lower(host), domain=lower(domain), checkin=lower(checkin), installdate=lower(installdate), installpatch=lower(installpatch), status=lower(status) | rex max_match=0 field=installpatch "(?<installpatch1>\S+)" | rex max_match=0 field=installpatch "\((?<installkb>\S+)\)"| fields - installpatch |   stats first(checkin) as checkin, values(domain) as domain, values(os) as os, values(installpatch1) as installpatch by host installdate | inputlookup append=true installed_patches.csv | outputlookup installed_patches.csv

[Subnet Breakdown]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 45 11 * * *
description = Disabled - New search created
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = | inputlookup asset_list.csv | rex max_match=0 field=ip "(?<ip2>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})" | mvexpand ip2 | eval _time=strptime(date, "%F") | stats latest(host) as host, latest(date) as date, latest(acas_date) as acas_date by ip2 | lookup asset_sub Subnet as ip2 OUTPUT VLAN VRF Location Subnet | outputlookup subnet_breakdown.csv

[Subnet Score]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 12 * * *
description = Updated Subnet Score csv search.  Needs Fixing
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = | tstats count where index=nessus AND source="cumulative" AND sourcetype="tenable:sc:vuln" AND ((Critical OR High OR Low OR Medium) AND "severity.id"!=0) OR ("severity.id"=0 AND (pluginID="19506" OR pluginID="45590")) by ip port repository.name pluginName pluginText pluginID severity.id \
	| rex field=pluginText "The remote operating system matched.*\n\n\s+(?<os>cpe:\/o:[^\s]+)"\
	| rename ip as ip2, pluginID as plugin, severity.id as severity\
	| lookup subnet_breakdown-test ip2 OUTPUT host date acas_date Subnet Location VRF VLAN \
	| eval scanned=if(plugin LIKE "%19506%", "yes", "no")\
	| fields host ip2 date plugin severity Location Subnet VLAN VRF scanned acas_date\
	| eval severity_level = case(severity=="4",4,severity=="3",3,severity=="2",2,severity=="1",1) \
	| eval weighting = case(severity=="4",10,severity=="3",10,severity=="2",4,severity=="1",1) \
	| stats sum(weighting) as weight, values(plugin) as plugin, first(date) as date, first(acas_date) as acas_date, first(Subnet) as subnet, values(VLAN) as vlan, values(VRF) as vrf, first(Location) as location, first(host) as host, values(scanned) as scanned by ip2 \
	| eval scanned=if(scanned LIKE "%yes%", "yes", "no")\
	| eval score=round(weight/15,2) | outputlookup subnet_score.csv

[Asset List Update DHCP1]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 35 0 * * *
description = Updates the DHCP data in the asset_list.csv
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 25
search = `asset_list_dhcp` | `asset_list_update` | outputlookup asset_list.csv

[Asset List Subnet Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 15 2 * * *
description = Updates Subnets info to asset list
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 10
search = | `asset_subnet_update` | outputlookup asset_list.csv

[Asset List Database]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 5 * * *
disabled = 1
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
enableSched = 1
search = | inputlookup  asset_list.csv | lookup asset_list_db host OUTPUT tag_func | outputlookup asset_list.csv

[subnet_info-total vrf]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
disabled = 1
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.type = singlevalue
search = | inputlookup asset_list.csv | rex max_match=0 field=sub_vrf "(?<sub_vrf2>\S+)" | mvexpand sub_vrf2 | stats dc(sub_vrf2)

[subnet_info - vrf]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 7 * * *
disabled = 1
dispatch.earliest_time = 0
display.general.type = statistics
enableSched = 1
search = | inputlookup asset_list.csv | rex max_match=0 field=sub_vrf "(?<sub_vrf2>\S+)" | mvexpand sub_vrf2 | dedup sub_vrf2 | table sub_vrf2 | rename sub_vrf2 as VRF | sort - VRF

[subnet_info - total vlan]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 7 * * *
disabled = 1
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.type = singlevalue
enableSched = 1
search = | inputlookup asset_list.csv | rex max_match=0 field=sub_vlan "(?<sub_vlan2>\S+)" | mvexpand sub_vlan2 | stats dc(sub_vlan2)

[subnet_info - total location]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 7 * * *
disabled = 1
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.type = singlevalue
enableSched = 1
search = | inputlookup asset_list.csv | rex max_match=0 field=sub_location "(?<sub_location2>\S+)" | mvexpand sub_location2 | stats dc(sub_location2)

[subnet_info - location]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 7 * * *
disabled = 1
dispatch.earliest_time = 0
display.general.type = statistics
enableSched = 1
search = | inputlookup asset_list.csv | rex max_match=0 field=sub_location "(?<sub_location2>\S+)" | mvexpand sub_location2| dedup sub_location2 | table sub_location2 | sort  sub_location2 | rename sub_location2 as Location

[subnet_info - Vlan]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 7 * * *
disabled = 1
dispatch.earliest_time = 0
display.general.type = statistics
enableSched = 1
search = | inputlookup asset_list.csv | rex max_match=0 field=sub_vlan "(?<sub_vlan2>\S+)" | mvexpand sub_vlan2| dedup sub_vlan2 | table sub_vlan2| sort  sub_vlan2 | rename sub_vlan2 as VLAN

[subnet_info - Total Subnets]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 7 * * *
disabled = 1
dispatch.earliest_time = 0
display.general.type = visualizations
display.visualizations.type = singlevalue
enableSched = 1
search = | inputlookup asset_list.csv | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | stats dc(sub_sub)

[subnet_info - Subnets]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 7 * * *
disabled = 1
dispatch.earliest_time = 0
display.general.type = statistics
enableSched = 1
search = | inputlookup asset_list.csv | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | dedup sub_sub | table sub_sub | sort  sub_sub | rename sub_sub as Subnet

[custom_reports-Subnets Missing]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 20 5 * * *
disabled = 1
dispatch.earliest_time = @d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = pie
display.visualizations.custom.type = VIS_horizon_chart_app.horizon_chart
display.visualizations.show = 0
enableSched = 1
search = | inputlookup asset_list.csv | replace " " with null in ip | where ip!="null" AND isnull(sub_subnet) | rex max_match=0 field=ip "(?<ip2>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d+)"  | mvexpand ip2 | rex field=ip2 max_match=0 "(?<ip3>\d{1,3}\.\d{1,3}\.\d{1,3})"  | dedup ip3 | rename ip3 as "Class C" | table "Class C" domain  | sort - "Class C"

[custom_reports-Server Uptime Clone]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 15 5 * * *
disabled = 1
dispatch.earliest_time = @d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = pie
display.visualizations.custom.type = VIS_horizon_chart_app.horizon_chart
display.visualizations.show = 0
enableSched = 1
search = | inputlookup asset_list.csv | search os_class="*server*" | eval date=strptime(date, "%F") | where date >= now()-(60*60*24*30)| eval date=strftime(date, "%F") |table date host domain ip tanium_uptime tanium_virtual tanium_username os sccm_managed tanium_managed hbss msl sccm_patchcycle sccm_patchwindow | eval Environment=if(domain LIKE "%tosd.mil%", "Test","Prod") | eval tanium_managed=if(tanium_managed="0",null(),tanium_managed) | replace "1" with Yes in sccm_managed tanium_managed hbss msl | replace "0" with No in tanium_managed | fillnull value=No sccm_managed tanium_managed hbss msl | rename sccm_managed AS SCCM, tanium_managed AS Tanium, hbss AS HBSS, msl AS MSL, sccm_patchcycle AS "Patch Cycle", sccm_patchwindow as "Patch Window" | sort - tanium_uptime

[custom_reports-Server Uptime]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 15 5 * * *
disabled = 1
dispatch.earliest_time = @d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = pie
display.visualizations.custom.type = VIS_horizon_chart_app.horizon_chart
display.visualizations.show = 0
enableSched = 1
search = | inputlookup asset_list.csv | search os_class="*server*" | eval date=strptime(date, "%F") | where date >= now()-(60*60*24*30)| eval date=strftime(date, "%F") |table date host domain ip tanium_uptime tanium_virtual tanium_username os sccm_managed tanium_managed hbss msl sccm_patchcycle sccm_patchwindow | eval Environment=if(domain LIKE "%tosd.mil%", "Test","Prod") | eval tanium_managed=if(tanium_managed="0",null(),tanium_managed) | replace "1" with Yes in sccm_managed tanium_managed hbss msl | replace "0" with No in tanium_managed | fillnull value=No sccm_managed tanium_managed hbss msl | rename sccm_managed AS SCCM, tanium_managed AS Tanium, hbss AS HBSS, msl AS MSL, sccm_patchcycle AS "Patch Cycle", sccm_patchwindow as "Patch Window" | sort - tanium_uptime

[custom_reports-Server Possible Decomm]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 10 5 * * *
disabled = 1
dispatch.earliest_time = @d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = pie
display.visualizations.custom.type = VIS_horizon_chart_app.horizon_chart
display.visualizations.show = 0
enableSched = 1
search = | inputlookup asset_list.csv |eval date=strptime(date,"%F"), sccm_discovery=strptime(sccm_discovery,"%F")| where date <=now()-(60*60*24*15) AND sccm_discovery>=now()-(60*60*24*15)  | eval date=strftime(date,"%F"), sccm_discovery=strftime(sccm_discovery,"%F") | search os_class="*server*" | table host domain ip date sccm_discovery sccm_ou tanium_ou os | sort - date

[custom_reports-Possible SIPR on NIPR]
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 5 5 * * *
disabled = 1
dispatch.earliest_time = 0
display.general.type = statistics
enableSched = 1
search = | inputlookup asset_list.csv | search domain=*smil.mil | table host ip mac domain fqdn  os date | eval date=strptime(date,"%F") | sort - date | eval date=strftime(date,"%F") | rename "date" as " Last Observed"

[acas_reports-ACAS Subnet Outliers]
action.email.sendcsv = 1
action.email.sendresults = 1
action.email.to = kimj.ctr@jdi.socom.mil
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 5 * * 1
disabled = 1
dispatch.latest_time = now
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
enableSched = 1
request.ui_dispatch_view = search
search = | inputlookup acas_assets.csv | inputlookup append=true all_nipr_vulnerabilities.csv | stats first(Repository) as Repository count by "IP Address" | lookup asset_sub Subnet AS "IP Address" OUTPUT VRF, VLAN, Subnet, Location | stats first(Repository) as Repository first(Subnet) as Subnet by "IP Address" | rename Subnet as sub_sub | eval acas=1, date="2018-05-11", acas_date="2018-05-11" \
	| inputlookup append=true asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*30) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*30)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*30)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*30)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*30)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*30)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*30)),sub_sub) | stats first(Repository) as Repository count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count by sub_sub\
	| join type=left sub_sub [| inputlookup acas_assets.csv | inputlookup append=true all_nipr_vulnerabilities.csv | stats count by "IP Address" | lookup asset_sub Subnet AS "IP Address" OUTPUT VRF, VLAN, Subnet, Location | stats first(Subnet) as Subnet by "IP Address" | rename Subnet as sub_sub | eval acas=1, date="2018-05-11", acas_date="2018-05-11" | inputlookup append=true asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*30) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*30)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*30)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*30)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*30)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*30)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*30)),sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count by sub_sub | transpose 0 column_name="tools" header_field="sub_sub" | stats stdev(*) as * | eval tools="stdev" | transpose 0 column_name="sub_sub" header_field="tools"]\
	| join type=left sub_sub [| inputlookup acas_assets.csv | inputlookup append=true all_nipr_vulnerabilities.csv | stats count by "IP Address" | lookup asset_sub Subnet AS "IP Address" OUTPUT VRF, VLAN, Subnet, Location | stats first(Subnet) as Subnet by "IP Address" | rename Subnet as sub_sub | eval acas=1, date="2018-05-11", acas_date="2018-05-11" | inputlookup append=true asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*30) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*30)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*30)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*30)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*30)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*30)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*30)),sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count by sub_sub | transpose 0 column_name="tools" header_field="sub_sub" | stats max(*) as * | eval tools="max" | transpose 0 column_name="sub_sub" header_field="tools"]\
	| eval lower=(max-stdev) | eval tanium-outlier=if('tanium-count'<lower,1,0), hbss-outlier=if('hbss-count'<lower,1,0), dhcp-outlier=if('dhcp-count'<lower,1,0), security-outlier=if('security-count'<lower,1,0), sccm-outlier=if('sccm-count'<lower,1,0), acas-outlier=if('acas-count'<lower,1,0)\
	| eval acas-perc=('acas-count'/max)\
	| sort 0 -max | where 'acas-outlier'==1 | fields sub_sub *-count acas-perc Repository  | eval percentage=round(('acas-perc' * 100),2) \
	| rename *-count as * \
	| rename tanium AS Tanium, sub_sub AS Subnet, acas AS ACAS, dhcp AS DHCP, security AS "Security Logs", sccm AS SCCM, hbss AS HBSS \
	| table Subnet Repository percentage ACAS DHCP HBSS SCCM "Security Logs" Tanium | sort percentage | rename percentage AS "Percentage Coverage" | fieldformat "Percentage Coverage"=tostring('Percentage Coverage') + "%" | outputlookup acas_outlier.csv

[User Location Main New]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 25 0 * * *
description = Updates to Main printer csv with new search
disabled = 1
enableSched = 1
search = | inputlookup append=true user_printer_table.csv \
	| fillnull value="null" user_printer\
	| eval user_printer=split(user_printer,";") \
	| mvexpand user_printer \
	| rex field=user_printer max_match=0 "^(?<building>.+?)\_(?<room>\S+)" \
	| fillnull value="null" building room user_room\
	| eval location=if(room="null", user_room, room)\
	| lookup user_building location OUTPUT b2 | fillnull value="null" b2 | outputlookup user_printer_main.csv

[sccm_reports-SCCM Subnet Outliers]
action.email.message.report = The attached report contains SCCM subnet outliers.
action.email.sendcsv = 1
action.email.sendpdf = 1
action.email.sendresults = 1
action.email.subject.report = SCCM Coverage Gap Report
action.email.to = kimj.ctr@jdi.socom.mil
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 6 * * 1
disabled = 1
enableSched = 1
search = | inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*30) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*30)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*30)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*30)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*30)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*30)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*30)),sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count by sub_sub\
	| join type=left sub_sub [| inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*30) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*30)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*30)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*30)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*30)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*30)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*30)),sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count by sub_sub | transpose 0 column_name="tools" header_field="sub_sub" | stats stdev(*) as * | eval tools="stdev" | transpose 0 column_name="sub_sub" header_field="tools"]\
	| join type=left sub_sub [| inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*30) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*30)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*30)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*30)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*30)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*30)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*30)),sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count by sub_sub | transpose 0 column_name="tools" header_field="sub_sub" | stats max(*) as * | eval tools="max" | transpose 0 column_name="sub_sub" header_field="tools"]\
	| eval lower=(max-stdev) | eval tanium-outlier=if('tanium-count'<lower,1,0), hbss-outlier=if('hbss-count'<lower,1,0), dhcp-outlier=if('dhcp-count'<lower,1,0), security-outlier=if('security-count'<lower,1,0), sccm-outlier=if('sccm-count'<lower,1,0), acas-outlier=if('acas-count'<lower,1,0)\
	| eval sccm-perc=('sccm-count'/max)\
	| sort 0 -max | where 'sccm-outlier'==1 | fields sub_sub *-count sccm-perc | eval percentage=round(('sccm-perc' * 100),2) \
	| rename *-count as * \
	| rename tanium AS Tanium, sub_sub AS Subnet, acas AS ACAS, dhcp AS DHCP, security AS "Security Logs", sccm AS SCCM, hbss AS HBSS \
	| table Subnet percentage ACAS DHCP HBSS SCCM "Security Logs" Tanium | sort percentage | rename percentage AS "Percentage Coverage" | fieldformat "Percentage Coverage"=tostring('Percentage Coverage') + "%" | outputlookup sccm_outlier.csv

[hbss_reports-HBSS Subnet Outliers]
action.email.message.report = The attached report contains HBSS coverage % by subnet.
action.email.sendcsv = 1
action.email.sendresults = 1
action.email.subject.report = HBSS Coverage Gap Report
action.email.to = kimj.ctr@jdi.socom.mil
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 4 * * 1
disabled = 1
dispatch.earliest_time = @d
dispatch.latest_time = now
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = pie
display.visualizations.custom.type = VIS_horizon_chart_app.horizon_chart
display.visualizations.show = 0
enableSched = 1
search = | inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*10) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*10)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*10)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*10)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*10)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*10)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*10)),sub_sub), splunk_subnet=case((splunk=1 AND strptime(splunk_date,"%F")>=now()-(60*60*24*10)), sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count count(splunk_subnet) as splunk-count by sub_sub \
	| join type=left sub_sub [| inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*10) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*10)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*10)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*10)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*10)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*10)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*10)),sub_sub), eval splunk_subnet=case((splunk=1 AND strptime(splunk_date,"%F")>=now()-(60*60*24*10)), sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count count(splunk_subnet) as splunk-count by sub_sub | transpose 0 column_name="tools" header_field="sub_sub" | stats stdev(*) as * | eval tools="stdev" | transpose 0 column_name="sub_sub" header_field="tools"]\
	| join type=left sub_sub [| inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*10) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*10)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*10)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*10)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*10)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*10)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*10)),sub_sub), splunk_subnet=case((splunk=1 AND strptime(splunk_date,"%F")>=now()-(60*60*24*10)), sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count count(splunk_subnet) as splunk-count by sub_sub | transpose 0 column_name="tools" header_field="sub_sub" | stats max(*) as * | eval tools="max" | transpose 0 column_name="sub_sub" header_field="tools"]\
	| eval lower=(max-stdev) | eval tanium-outlier=if('tanium-count'<lower,1,0), splunk-outlier=if('splunk-count'<lower,1,0), hbss-outlier=if('hbss-count'<lower,1,0), dhcp-outlier=if('dhcp-count'<lower,1,0), security-outlier=if('security-count'<lower,1,0), sccm-outlier=if('sccm-count'<lower,1,0), acas-outlier=if('acas-count'<lower,1,0)\
	| eval hbss-perc=('hbss-count'/max)\
	| sort 0 -max | where 'hbss-outlier'==1 | fields sub_sub *-count hbss-perc | eval percentage=round(('hbss-perc' * 100),2) \
	| rename *-count as * \
	| rename tanium AS Tanium, sub_sub AS Subnet, acas AS ACAS, dhcp AS DHCP, security AS "Security Logs", sccm AS SCCM, hbss AS HBSS, splunk as Splunk \
	| table Subnet  percentage ACAS DHCP HBSS SCCM Splunk "Security Logs" Tanium | sort percentage | rename percentage AS "Percentage Coverage" | fieldformat "Percentage Coverage"=tostring('Percentage Coverage') + "%" | outputlookup hbss_outlier.csv

[splunk_reports-Splunk Subnet Outliers]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 6 * * 1
disabled = 1
dispatch.earliest_time = 0
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = pie
display.visualizations.custom.type = VIS_horizon_chart_app.horizon_chart
display.visualizations.show = 0
enableSched = 1
search = | inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*10) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*10)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*10)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*10)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*10)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*10)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*10)),sub_sub), splunk_subnet=case((splunk=1 AND strptime(splunk_date,"%F")>=now()-(60*60*24*10)), sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count count(splunk_subnet) as splunk-count by sub_sub \
	| join type=left sub_sub [| inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*10) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*10)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*10)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*10)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*10)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*10)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*10)),sub_sub), eval splunk_subnet=case((splunk=1 AND strptime(splunk_date,"%F")>=now()-(60*60*24*10)), sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count count(splunk_subnet) as splunk-count by sub_sub | transpose 0 column_name="tools" header_field="sub_sub" | stats stdev(*) as * | eval tools="stdev" | transpose 0 column_name="sub_sub" header_field="tools"]\
	| join type=left sub_sub [| inputlookup asset_list.csv |  eval date=strptime(date,"%F") | where date >= now()-(60*60*24*10) | rex max_match=0 field=sub_subnet "(?<sub_sub>\S+)" | mvexpand sub_sub | eval tanium_subnet=case((tanium_managed=1 AND strptime(tanium_date,"%F")>=now()-(60*60*24*10)), sub_sub), hbss_subnet=case((hbss=1 AND strptime(hbss_date,"%F")>=now()-(60*60*24*10)),sub_sub), dhcp_subnet=case((dhcp=1 AND strptime(dhcp_date,"%F")>=now()-(60*60*24*10)),sub_sub), security_subnet=case((security=1 AND strptime(security_date,"%F")>=now()-(60*60*24*10)), sub_sub), acas_subnet=case((acas=1 AND strptime(acas_date,"%F")>=now()-(60*60*24*10)), sub_sub), sccm_subnet=case((sccm_managed=1 AND strptime(sccm_date,"%F")>=now()-(60*60*24*10)),sub_sub), splunk_subnet=case((splunk=1 AND strptime(splunk_date,"%F")>=now()-(60*60*24*10)), sub_sub) | stats count(tanium_subnet) as tanium-count count(hbss_subnet) as hbss-count count(dhcp_subnet) as dhcp-count count(security_subnet) as security-count count(sccm_subnet) as sccm-count count(acas_subnet) as acas-count count(splunk_subnet) as splunk-count by sub_sub | transpose 0 column_name="tools" header_field="sub_sub" | stats max(*) as * | eval tools="max" | transpose 0 column_name="sub_sub" header_field="tools"]\
	| eval lower=(max-stdev) | eval tanium-outlier=if('tanium-count'<lower,1,0), splunk-outlier=if('splunk-count'<lower,1,0), hbss-outlier=if('hbss-count'<lower,1,0), dhcp-outlier=if('dhcp-count'<lower,1,0), security-outlier=if('security-count'<lower,1,0), sccm-outlier=if('sccm-count'<lower,1,0), acas-outlier=if('acas-count'<lower,1,0)\
	| eval splunk-perc=('splunk-count'/max)\
	| sort 0 -max | where 'splunk-outlier'==1 | fields sub_sub *-count splunk-perc  | eval percentage=round(('splunk-perc' * 100),2) \
	| rename *-count as * \
	| rename tanium AS Tanium, sub_sub AS Subnet, acas AS ACAS, dhcp AS DHCP, security AS "Security Logs", sccm AS SCCM, hbss AS HBSS, splunk as Splunk \
	| table Subnet  percentage ACAS DHCP HBSS SCCM Splunk "Security Logs" Tanium | rename percentage AS "Percentage Coverage" | fieldformat "Percentage Coverage"=tostring('Percentage Coverage') + "%" | outputlookup splunk_outlier.csv

[Subnet Score Old]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
description = Original Subnet Score search, saved incase backup is needed, can delete once new search is verified
disabled = 1
search = | inputlookup acas_assets.csv | inputlookup append=true all_nipr_vulnerabilities.csv | rename "IP Address" as ip2, Severity as severity, Plugin as plugin | lookup subnet_breakdown.csv ip2 OUTPUT host date Subnet Location VRF VLAN | eval scanned=if(plugin=19506, "yes", "no") | fields host ip2 date plugin severity Location Subnet VLAN VRF scanned | eval severity_level = case(severity=="Critical",4,severity=="High",3,severity=="Medium",2,severity=="Low",1) \
	| eval weighting = case(severity=="Critical",10,severity=="High",10,severity=="Medium",4,severity=="Low",1)\
	| stats sum(weighting) as weight, values(plugin) as plugin, values(date) as date, values(Subnet) as subnet, values(VLAN) as vlan, values(VRF) as vrf, values(Location) as location,values(host) as host, values(scanned) as scanned by ip2 | eval score=round(weight/15,2) | outputlookup subnet_score.csv

[Database Information]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 4 * * *
disabled = 1
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
enableSched = 1
search = index=tanium sourcetype="tanium:connect:syslog" Question_Name="Database-Discovery" \
	| table Computer_Name Service SQL_Database_Count IPv4_Address\
	| rename Service as Oracle, SQL_Database_Count as SQL, IPv4_Address as ip\
	| eval  SQL=if(SQL="[no results]","no","yes"), Oracle=if(Oracle="[no results]", "no","yes")\
	| eval stuff=if(Oracle="no" AND SQL="no", "yes", "no")\
	| search stuff="no"\
	| eval Computer_Name=lower(Computer_Name)\
	| eval tag_func=if(Oracle="yes", "db_oracle", "db_sql")\
	| rex field=Computer_Name "^(?<host>[\w\-\d]*)(?:\.(?<domain>[^\s]+)|\.|$)"\
	| fields - Computer_Name stuff\
	| stats values(ip) as ip, values(Oracle) as Oracle , values(SQL) as SQL, values(domain) as domain, values(tag_func) as tag_func by host\
	| inputlookup append=true asset_list_db\
	| stats first(*) as * by host\
	| outputlookup asset_list_db.csv

[Disk Drive Report]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 1 * * *
description = Updates Disk Drive csv daily
disabled = 1
dispatch.earliest_time = -24h
enableSched = 1
search = index=tanium  sourcetype="tanium:connect:syslog"  Question_Name="Splunk-Disk-Drive-Details-Windows" | table Computer_Name Drive_Letter Free_Space Size  | rename Computer_Name as fqdn, Drive_Letter as drive, Free_Space as free, Size as size \
	| rex field=fqdn "^(?<host>[\w\-\d]*)(?:\.(?<domain>.*)|$)" | fields - fqdn | eval host=lower(host), domain=lower(domain) | lookup asset_list host OUTPUT os os_class domain date | inputlookup append=true asset_drive.csv | stats first(*) as * by host drive | outputlookup asset_drive.csv

[JP54 Monthly CI baseline alert]
action.email = 1
action.email.inline = 1
action.email.sendcsv = 1
action.email.sendresults = 1
action.email.to = kimj.ctr@jdi.socom.mil
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 0 6 5 * *
description = Alert sent to jp54 on monthly abasis
disabled = 1
dispatch.earliest_time = -1mon
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = | inputlookup asset_list.csv |search tanium_type=* |eval t_date=strptime(date, "%F") |eval Type=upper(tanium_type)\
	|  where t_date >= now()-(60*60*24*30)|stats count by Type

[Jp54 Monthly Report]
action.email = 1
action.email.sendcsv = 1
action.email.sendpdf = 1
action.email.sendresults = 1
action.email.to = kimj.ctr@jdi.socom.mil
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 0 6 5 * *
disabled = 1
dispatch.earliest_time = -1mon
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = | inputlookup asset_list.csv  |eval t_date=strptime(date, "%F") | where t_date >= now()-(60*60*24*30)|eval Model=upper(tanium_model),  "Operating System"=upper(os)| fillnull value="x" os_class msl_vendor os_type Model "Operating System" | stats count by Model, "Operating System" os_class os_type msl_vendor |sort Model |addtotals row=f col=t label=Total labelfield=Model

[OMC Systems]
action.email = 1
action.email.sendcsv = 1
action.email.sendresults = 1
action.email.to = kimj.ctr@jdi.socom.mil
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 30 11 * * *
description = Daily Report of OMC systems
disabled = 1
enableSched = 1
search = | inputlookup asset_list.csv \
	| eval date=strptime(date, "%F") \
	| where date >= now()-(60*60*24*30) \
	| where tanium_ou LIKE "%ou=defense,ou=omc%" \
	| fields host date ip os tanium_build mac tanium_serial tanium_ou tanium_model tanium_username tanium_sub\
	| eval date=strftime(date, "%F")

[OMC Daily System Software]
action.email = 1
action.email.sendcsv = 1
action.email.sendresults = 1
action.email.to = kimj.ctr@jdi.socom.mil
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 30 11 * * *
disabled = 1
enableSched = 1
search = | inputlookup asset_list.csv \
	| eval date=strptime(date,"%F") \
	| where date >= now()-(60*60*24*30) \
	| where tanium_ou LIKE "%ou=defense,ou=omc%" \
	| lookup applications.csv host OUTPUT app1 \
	| table host app1 \
	| rex field=app1 max_match=0 "^(?<app2>\S+)\s" \
	| mvexpand app2 \
	| fields - app1 \
	| stats values(*) as * by host \
	| rex field=app2 "^(?<app>\S+)\_\_(?<vers>\S+)" \
	| fields - app2 | table host app vers

[Bitlocker Report]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 8 * * *
disabled = 1
dispatch.earliest_time = -d
dispatch.latest_time = now
enableSched = 1
search = index=tanium Question_Name="BitLocker-Information-and-TPM-Information" | where Drive="C:"\
	| fields Computer_Name Protection_Status Encryption_Method _time Has_TPM Enabled Owned TPM_Version\
	| table Computer_Name Protection_Status Encryption_Method _time Has_TPM Enabled Owned TPM_Version\
	| rename Computer_Name as fqdn \
	| eval date=strftime(_time, "%F")\
	| eval Protection_Status=case(Protection_Status LIKE "%Off%","Off", Protection_Status LIKE "%On%", "On") \
	| eval fqdn=lower(fqdn) \
	| rex field=fqdn "^(?<host>[\w\-\d]*)(?:\.(?<domain>.*)|$)" \
	| lookup asset_list host OUTPUT os_class os_func tanium_vdi ip \
	| fields - fqdn \
	| table host domain date ip os_func tanium_vdi Protection_Status Encryption_Method Has_TPM Enabled Owned TPM_Version\
	| inputlookup append=true bitlocker.csv \
	| stats first(*) as * by host\
	| outputlookup bitlocker.csv

[Software Important]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 10 * * *
disabled = 1
dispatch.earliest_time = -d
dispatch.latest_time = now
enableSched = 1
search = index=tanium sourcetype=tanium:connect:syslog Question_Name="Splunk-Computer-Name-and-Installed-Applications" \
	| fields Computer_Name Name Version _time IPv4_Address \
	| where Name LIKE "%ActivClient%" OR Name LIKE "%Tychon%" OR Name LIKE "%ACCM%" OR Name LIKE "%McAfee-DLP-Endpoint%" OR Name LIKE "%McAfee-Host%" OR Name LIKE "%Microsoft-Monitoring-Agent%" OR Name LIKE "%UniversalForwarder%"\
	| eval Name=if(Name LIKE "%ActivClient%", "ActivClient",Name)\
	| rex field=Computer_Name "^(?<host>[\w\-\d]*)(?:\.(?<domain>.*)|$)" \
	| rename IPv4_Address as ip\
	| eval date=strftime(_time, "%F") \
	| fields - Computer_Name \
	| fields host domain Name Version date ip\
	| table host domain Name Version date ip\
	| lookup asset_list host OUTPUT os_class\
	| inputlookup append=true importantapps.csv \
	| stats first(*) as * by host Name\
	| table date host domain ip os_class Name Version\
	| outputlookup importantapps.csv

[Software report]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 11 * * *
disabled = 1
dispatch.earliest_time = -2h@d
dispatch.latest_time = now
enableSched = 1
search = index=tanium sourcetype=tanium:connect:syslog Question_Name="Splunk-Computer-Name-and-Installed-Applications" \
	| rex field=Computer_Name "^(?<host>[\w\-\d]*)(?:\.(?<domain>.*)|$)" \
	| rename IPv4_Address as ip, Name as application, Operating_System as os, Version as version\
	| eval date=strftime(_time, "%F")\
	| fields host domain ip date application os version os1\
	| eval host=lower(host), application=lower(application), version=lower(version), domain=lower(domain), ip=lower(ip), os=lower(os)\
	| stats list(version) as version, list(application) as application, first(domain) as domain, first(ip) as ip, first(os) as os, first(date) as date by host\
	| eval app1=mvzip(application, version, "__")\
	| fields - version application | mvcombine app1 | inputlookup append=true applications.csv | stats first(*) as * by host | eval os1=if(like(os, "%server%"), "server", "workstation") | outputlookup applications.csv

[AD Resource Printer LDAP]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 55 22 * * *
disabled = 1
dispatch.earliest_time = -24h@d
enableSched = 1
search = | ldapsearch search="(objectClass=printQueue)" attrs="location, distinguishedName, whenChanged, whenCreated, shortServerName, printerName" \
	| search printerName=* \
	| table location, distinguishedName, whenChanged, whenCreated, shortServerName, printerName, _time\
	| eval ad_date=strftime(_time, "%F") \
	| rename printerName as host, distinguishedName as ad_ou, whenChanged as ad_change, whenCreated as ad_creation, location as ad_location, shortServerName as ad_printserver\
	| eval ad=1 \
	| eval ad_print=1\
	\
	| rex field=ad_creation "^(?<ad_creation>\d{8})" \
	| rex field=ad_change "^(?<ad_change>\d{8})" \
	| eval ad_creation=strptime(ad_creation, "%Y%m%d"), ad_change=strptime(ad_change, "%Y%m%d") \
	| eval ad_creation=strftime(ad_creation, "%F"), ad_change=strftime(ad_change, "%F"), ad_lastlogon=strftime(ad_lastlogon, "%F") \
	| eval ad_domain="rsrc.osd.mil"\
	| fields - _time ad_host \
	| eval ad_location=if(isnull(ad_location),"null",ad_location)\
	| eval host=lower(host), ad_change=lower(ad_change), ad_creation=lower(ad_creation), ad_location=lower(ad_location), ad_ou=lower(ad_ou), ad_printserver=lower(ad_printserver) | inputlookup append=true ad_list.csv | stats first(*) as * by host  | outputlookup ad_list.csv

[AD Resource LDAP]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 10 23 * * *
disabled = 1
dispatch.earliest_time = -24h
dispatch.latest_time = now
enableSched = 1
search = | ldapsearch search="(objectClass=computer)" attrs="cn, dNSHostName, distinguishedName, lastLogonTimestamp, objectSid, operatingSystem, pwdLastSet, operatingSystemVersion, roomNumber, whenChanged, whenCreated, userAccountControl" \
	| search cn="*" \
	| table cn, dNSHostName, distinguishedName, lastLogonTimestamp, objectSid, operatingSystem, pwdLastSet, operatingSystemVersion, roomNumber, whenChanged, whenCreated, userAccountControl, _time\
	| eval ad_date=strftime(_time, "%F") \
	| rename cn as host, dNSHostName as ad_dnsname, distinguishedName as ad_ou, lastLogonTimestamp as ad_lastlogon, objectSid as ad_sid, operatingSystem as ad_os, operatingSystemVersion as ad_vers, whenChanged as ad_change, whenCreated as ad_creation, PasswordLastSet as ad_passlastset, roomNumber as ad_room, userAccountControl as ad_disabled, pwdLastSet as ad_pwlastset\
	| eval ad=1 \
	| eval ad_lastlogon=strptime(ad_lastlogon, "%F") \
	| eval ad_pwlastset=strptime(ad_pwlastset, "%F") \
	| rex field=ad_creation "^(?<ad_creation>\d{8})" \
	| rex field=ad_change "^(?<ad_change>\d{8})" \
	| eval ad_creation=strptime(ad_creation, "%Y%m%d"), ad_change=strptime(ad_change, "%Y%m%d") \
	| eval ad_creation=strftime(ad_creation, "%F"), ad_change=strftime(ad_change, "%F"), ad_lastlogon=strftime(ad_lastlogon, "%F"), ad_pwlastset=strftime(ad_pwlastset, "%F")  \
	| rex field=ad_dnsname "^(?<ad_host>[\w\-\d]*)(?:\.(?<ad_domain1>[^\s]+)|\.|$)" \
	| fields - _time ad_host \
	| eval ad_domain="rsrc.osd.mil"\
	| eval ad_room=if(isnull(ad_room),"null",ad_room) \
	| eval host=lower(host), ad_room=lower(ad_room), ad_disabled=lower(ad_disabled), ad_dnsname=lower(ad_dnsname), ad_ou=lower(ad_ou), ad_lastlogon=lower(ad_lastlogon), ad_sid=lower(ad_sid), ad_os=lower(ad_os), ad_vers=lower(ad_vers), ad_change=lower(ad_change), ad_creation=lower(ad_creation) \
	| eval ad_disabled2=if(ad_disabled LIKE "%disable%", "1", "0") \
	| fields - ad_disabled ad_dnsname ad_domain1 | inputlookup append=true ad_list.csv | stats first(*) as * by host | outputlookup ad_list.csv

[User List Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 30 23 * * *
description = Updates main User list from other domains
disabled = 1
enableSched = 1
search = | inputlookup append=true user_ext_list.csv | inputlookup append=true  user_dmz_list.csv | inputlookup append=true user_usr_list.csv | inputlookup append=true user_rsrc_list.csv | inputlookup append=true user_es_list.csv | inputlookup append=true user_hqda_list.csv | inputlookup append=true user_osdroot_list.csv | stats first(user*) as user* by user_samx |   outputlookup user_list_base.csv

[User OU update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 5 0 * * *
disabled = 1
enableSched = 1
search = | inputlookup user_list_main.csv  | eval user_t1=mvindex(split(user_dn1,","),-1) | rex field=user_t1 "^ou=(?<user_t1>.*)" | eval user_t2=mvindex(split(user_dn1,","),-2) | rex field=user_t2 "^ou=(?<user_t2>.*)" | eval user_t3=mvindex(split(user_dn1,","),-3) | rex field=user_t3 "^ou=(?<user_t3>.*)" | eval user_t4=mvindex(split(user_dn1,","),-4) | rex field=user_t4 "^ou=(?<user_t4>.*)" | eval user_t5=mvindex(split(user_dn1,","),-5) | rex field=user_t5 "^ou=(?<user_t5>.*)" | eval user_t6=mvindex(split(user_dn1,","),-6) | rex field=user_t6 "^ou=(?<user_t6>.*)" |  eval user_t7=mvindex(split(user_dn1,","),-7) | rex field=user_t7 "^ou=(?<user_t7>.*)" | eval user_t8=mvindex(split(user_dn1,","),-8) | rex field=user_t8 "^ou=(?<user_t8>.*)" | eval user_domain1=case(user_domain="es", "es.pentagon.mil", user_domain="ext", "ext.rsrc.osd.mil", user_domain="rsrc", "rsrc.osd.mil", user_domain="usr", "usr.osd.mil", user_domain="dmz", "dmz.local", user_domain="osd","osd.mil") | eval user_sam2=user_domain1.".".user_sam | outputlookup user_list_main.csv

[User Location]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 20 0 * * *
disabled = 1
enableSched = 1
search = | inputlookup append=true asset_list.csv | where isnotnull(tanium_username) | eval domain1=case(domain="usr.osd.mil", "usr", domain="rsrc.osd.mil", "rsrc", domain="ext.rsrc.osd.mil", "ext", domain="es.pentagon.mil","es") | eval asset_sam=domain1.".".tanium_username | fields host asset_sam date domain ad_ou tanium_virtual | lookup user_list_main user_samx as asset_sam OUTPUT  user_fullname user_email user_room user_sam user_printer user_samx user_lastlogon1 user_dn1  | fields user_fullname user_email user_lastlogon1 user_room user_sam user_printer host asset_sam date domain user_dn1 ad_ou tanium_virtual| outputlookup user_printer_table.csv

[Asset List User]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 20 3 * * *
disabled = 1
dispatch.earliest_time = -d@h
enableSched = 1
search = | inputlookup asset_list.csv | eval d2=case(domain="usr.osd.mil", "usr", domain="ext.rsrc.osd.mil", "ext", domain="rsrc.osd.mil", "rsrc", domain="dahq.ds.army.mil", "hqda") | eval d3=d2.".".tanium_username | lookup user_list_main user_samx as d3 OUTPUT user_email user_fullname | fields - d2 d3 | outputlookup asset_list.csv

[Patches_Phase_part2]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 50 5 * * *
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = index=* sourcetype="WinEventLog:System" EventCode=19 SourceName="Microsoft-Windows-WindowsUpdateClient" \
	| eval package_title=package_title.";" \
	| rename EventCode as event \
	| fields host package package_title event _time \
	| table _time host package package_title event \
	| eval time=strftime(_time, "%F") \
	| stats list(package) as package, list(package_title) as package_title, values(event) as event by host time \
	| eval host=lower(host) \
	| eval patch=1 \
	\
	| lookup asset_list.csv host OUTPUT domain tanium_uptime sccm_patchcycle sccm_patchwindow os os_class \
	| where os_class="server" \
	| fillnull value="n/a" sccm_patchcycle sccm_patchwindow \
	| rex field=sccm_patchcycle max_match=0 "(?<sccm_cycle>no reboot|reboot|pilot reboot|available)" \
	| rex field=sccm_patchwindow max_match=0 "(?<sccm_phase>\S{3} thurs)" \
	| table host os sccm* tanium_uptime package* event time patch domain \
	| replace "no reboot" with "none" in sccm_cycle \
	| eval reboot_yes=case(sccm_cycle LIKE "reboot", "yes") \
	| eval reboot_no=case(sccm_cycle LIKE "none", "yes") \
	| eval reboot_manual=case(sccm_cycle LIKE "available", "yes") \
	| eval phase_manual=case(sccm_patchwindow LIKE "%na manual%","yes") \
	| eval phase_na=case(sccm_patchwindow LIKE "%servers not%", "yes", sccm_patchwindow LIKE "%no collection%", "yes") \
	| eval phase_old=case(sccm_phase LIKE "%2nd%", "yes",sccm_phase LIKE "%3rd%", "yes", sccm_phase LIKE "%4th%", "yes", sccm_phase LIKE "%1st%", "yes") \
	| eval phase_1=case(sccm_patchwindow LIKE "%tues_1%", "yes") \
	| eval phase_2=case(sccm_patchwindow LIKE "%thurs_2%", "yes") \
	| eval phase_3=case(sccm_patchwindow LIKE "%sat_3%", "yes") \
	| eval phase_comp1=case(sccm_patchwindow LIKE "%compt_1%", "yes") \
	| eval phase_comp2=case(sccm_patchwindow LIKE "%compt_2%", "yes") \
	| fillnull value="no" phase_1 phase_2 phase_3 phase_manual phase_na reboot_manual reboot_no reboot_yes phase_old phase_comp1 phase_comp2 \
	| fields - sccm* \
	| fillnull value="n/a" tanium_uptime \
	| inputlookup append=true patchphase2.csv \
	| stats first(*) as * by host time \
	| outputlookup patchphase2.csv

[PatchPhase2-2]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 6 * * *
disabled = 1
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = index=tanium  sourcetype="tanium:connect:syslog"  Question_Name="Splunk-Disk-Drive-Details-Windows" | table Computer_Name Drive_Letter Free_Space Size | rename Computer_Name as fqdn, Drive_Letter as drive, Free_Space as free, Size as size | where drive="C:"\
	| rex field=fqdn "^(?<host>[\w\-\d]*)(?:\.(?<domain>.*)|$)" | fields - fqdn | eval host=lower(host), domain=lower(domain) |  inputlookup append=true patchphase2.csv  | eval time=split(time," ") | stats first(domain) as domain, values(drive) as drive, values(event) as event, first(free) as free, values(os) as os, values(package*) as package*, values(patch) as patch, values(phase*) as phase*, values(reboot*) as reboot*, first(size) as size, first(tanium_uptime) as tanium_uptime by host time| where patch=1 | outputlookup patchphase2.csv

[Risk Score Subnet Asset search]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 9 * * 4
description = Creating CSV for Risk Score dashboard
disabled = 1
dispatch.earliest_time = -24h
dispatch.latest_time = now
enableSched = 1
search = index=nessus sourcetype=stash | eval ip=split(ip,"|") | fields riskScore ip lastSeen system  | inputlookup append=true subnet_score2.csv |stats first(*) as * by ip | lookup local=true asset_sub Subnet as ip OUTPUT vrf Location Subnet | eval _time=lastSeen | fields system riskScore ip lastSeen VLAN vrf Location Subnet time | table system riskScore ip lastSeen VLAN vrf Location Subnet _time  |  stats latest(*) as * by ip |   lookup local=true asset_list host as system OUTPUT domain date ou1 ou_t1 ou_t2 ou_t3 ou_t4 ou_t5 ou_t6 ou_t7 ou_t8 os_class os |  eval _time=lastSeen |  stats latest(*) as * by ip  |  fillnull value="n/a" domain os_class ou_t1 ou1 ou_t2 ou_t3 ou_t4 ou_t5 ou_t6 ou_t7 ou_t8 | replace " " with "n/a" in ou_t1 domain os_class ou1 ou_t2 ou_t3 ou_t4 ou_t5 ou_t6 ou_t7 ou_t8 | outputlookup subnet_score2.csv

[Risk Score Subnet Asset Search2]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 9 * * 4
description = Testing new Risk Score by subnet dashboard
disabled = 1
dispatch.earliest_time = -24h
enableSched = 1
search = index=nessus sourcetype=stash \
	| eval ip=split(ip,"|") \
	\
	| fields riskScore ip lastSeen system \
	| table riskScore ip lastSeen system \
	| inputlookup append=true asset_list.csv\
	| eval ip=split(ip, " ")\
	| fields ip riskScore lastSeen system host domain date ou* os_class os os_vdi\
	| sort 0 - lastSeen\
	| rex field=system "^(?<system1>[^.]+)\.(?<domain1>\S+)"\
	| eval system=if(isnotnull(system1), system1, system)\
	| eval system=if(isnull(system), host, system)\
	\
	| stats first(ip) as ip, first(riskScore) as riskScore, first(lastSeen) as lastSeen, values(domain) as domain, values(domain1) as domain1, values(ou*) as ou*, values(os*) as os*, values(date) as date by system\
	| eval domain=if(isnull(domain),domain1,domain)\
	| eval domain=if(isnull(domain),"unknown",domain)\
	| where isnotnull(lastSeen)\
	| eval scan=if(lastSeen >=now()-(60*60*24*7),"1","0")\
	| eval domain=case(domain="DMZ.Local", "dmz.local", domain="ar","ar.ds.army.mil", domain LIKE "%dahq%","dahq.ds.army.mil", domain="es", "es.pentagon.mil", domain="external", "ext.rsrc.osd.mil", domain="lsb", "lsb.pfpa.mil", domain="eccdomain","eccdomain.esmc.pentagon.mil", domain="terminal", "terminal.eccdomain.esmc.pentagon.mil", true(),domain) \
	| eval domain=case(isnull(domain) AND scan=1, "unknown", true(), domain)\
	| lookup local=true asset_sub Subnet as ip OUTPUT vrf Location Subnet\
	| eval _time=lastSeen\
	| inputlookup append=true riskscore.csv\
	| fillnull value="n/a" domain os_class ou_t1 ou1 ou_t2 ou_t3 ou_t4 ou_t5 ou_t6 ou_t7 ou_t8 os_vdi\
	| replace " " with "n/a" in ou_t1 domain os_class ou1 ou_t2 ou_t3 ou_t4 ou_t5 ou_t6 ou_t7 ou_t8 os_vdi\
	| fields - domain1\
	| stats latest(*) as * by ip\
	| outputlookup riskscore.csv

[User Building New]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
description = Updates building And Room Number
disabled = 1
search = | inputlookup append=true user_printer_table.csv \
	| fillnull value="null" user_printer\
	| eval user_printer=split(user_printer,";")\
	| mvexpand user_printer\
	| rex field=user_printer max_match=0 "^(?<building>.+?)\_(?<room>\S+)"\
	| eval location=if(isnull(room), user_room, room)\
	| fillnull value="null" building room\
	| stats count by user_printer user_room location building room | search building!=null\
	| dedup location | stats values(building) as b2 by location | replace " *" with * in b2 | outputlookup user_building.csv

[Asset List Update Cylance]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 30 0 * * *
description = Updates the Cylance data in the asset_list.csv
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 15
search = | `cylance_list_update` | `asset_list_update` | outputlookup asset_list.csv

[Asset List Update ACAS]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 45 0 * * *
description = Updates the ACAS data in the asset_list.csv
dispatch.earliest_time = -24h
dispatch.latest_time = now
enableSched = 1
schedule_window = 25
search = | `acas_list_update` | `asset_list_update` | outputlookup asset_list.csv

[Asset List Update HBSS]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 15 1 * * *
description = Updates HBSS data into asset list
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 15
search = `asset_list_hbss` | `asset_list_update` | outputlookup asset_list.csv

[Asset List Update HBSS managed]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 30 1 * * *
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = index=epo-v5 sourcetype="mcafee:epo:rsd" | rename ComputerName as host, LastCommunicationTime as hbss_checkin  |  rex field=hbss_checkin "^(?<hbss_checkin>\d{4}\-\d{2}\-\d{2})" | eval host=lower(host), hbss_checkin=lower(hbss_checkin) | eval hbss_checkin=strptime(hbss_checkin, "%F")   | table hbss* host | inputlookup append=true asset_list.csv |  stats first(*) as * by host | eval hbss_managed=case(hbss_checkin >= now()-(60*60*24*3), "0", isnull(hbss_checkin) AND hbss=1, "1") | eval hbss_checkin=strftime(hbss_checkin, "%F") | outputlookup asset_list.csv

[Asset List Update Splunk]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 15 2 * * *
description = updates Asset list with splunk info
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 10
search = `splunk_asset_update`|`asset_list_update` | outputlookup asset_list.csv

[AD LDAP]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 30 2 * * *
dispatch.earliest_time = -24h
dispatch.latest_time = now
enableSched = 1
search = | ldapsearch search="(objectClass=computer)" attrs="cn, dNSHostName, distinguishedName, lastLogonTimestamp, objectSid, operatingSystem, pwdLastSet, operatingSystemVersion, roomNumber, whenChanged, whenCreated, userAccountControl" \
	| search cn="*" \
	| table cn, dNSHostName, distinguishedName, lastLogonTimestamp, objectSid, operatingSystem, pwdLastSet, operatingSystemVersion, roomNumber, whenChanged, whenCreated, userAccountControl, _time\
	| eval ad_date=strftime(_time, "%F") \
	| rename cn as host, dNSHostName as ad_dnsname, distinguishedName as ad_ou, lastLogonTimestamp as ad_lastlogon, objectSid as ad_sid, operatingSystem as ad_os, operatingSystemVersion as ad_vers, whenChanged as ad_change, whenCreated as ad_creation, PasswordLastSet as ad_passlastset, roomNumber as ad_room, userAccountControl as ad_disabled, pwdLastSet as ad_pwlastset\
	| eval ad=1 \
	| eval ad_lastlogon=strptime(ad_lastlogon, "%F") \
	| eval ad_pwlastset=strptime(ad_pwlastset, "%F") \
	| rex field=ad_creation "^(?<ad_creation>\d{8})" \
	| rex field=ad_change "^(?<ad_change>\d{8})" \
	| eval ad_creation=strptime(ad_creation, "%Y%m%d"), ad_change=strptime(ad_change, "%Y%m%d") \
	| eval ad_creation=strftime(ad_creation, "%F"), ad_change=strftime(ad_change, "%F"), ad_lastlogon=strftime(ad_lastlogon, "%F"), ad_pwlastset=strftime(ad_pwlastset, "%F") \
	| rex field=ad_dnsname "^(?<ad_host>[\w\-\d]*)(?:\.(?<ad_domain>1[^\s]+)|\.|$)" \
	| fields - _time ad_host\
	| eval ad_domain="hq.jdi.army.mil"\
	| eval ad_room=if(isnull(ad_room),"null",ad_room) \
	| eval host=lower(host), ad_room=lower(ad_room), ad_disabled=lower(ad_disabled), ad_dnsname=lower(ad_dnsname), ad_ou=lower(ad_ou), ad_lastlogon=lower(ad_lastlogon), ad_sid=lower(ad_sid), ad_os=lower(ad_os), ad_vers=lower(ad_vers), ad_change=lower(ad_change), ad_creation=lower(ad_creation) \
	| eval ad_disabled2=if(ad_disabled LIKE "%disable%", "1", "0") \
	| fields - ad_disabled ad_dnsname ad_domain1 | inputlookup append=true ad_list.csv | stats first(*) as * by host | outputlookup ad_list.csv

[AD List Main]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 45 2 * * *
description = Updates AD List to show only hosts still on network
dispatch.earliest_time = -24h@d
enableSched = 1
search = | inputlookup ad_list.csv | eval ad_date=strptime(ad_date, "%F") | eval ad_print=if(ad_print="1","1","0") | where ad_date >= now()-(60*60*24*2) | eval ad_date=strftime(ad_date, "%F") |  outputlookup ad_list_main.csv

[Asset List AD Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 3 * * *
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = | inputlookup ad_list_main.csv | `asset_list_update` | outputlookup asset_list.csv

[GPO]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 0 * * *
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
search = | ldapsearch search="(objectClass=groupPolicyContainer)" attrs="displayName, cn, distinguishedName, objectGUID, whenChanged, whenCreated" \
	| search displayName="*" \
	| table displayName, cn, distinguishedName, objectGUID, whenChanged, whenCreated\
	| rename cn as gpo_id, distinguishedName as gpo_ou,  whenChanged as gpo_change, whenCreated as gpo_creation, displayName as gpo_name, objectGUID, as gpo_guid\
	| eval gpo_change=strptime(gpo_change, "%Y-%m-%d %H:%M:%S%Z")\
	| eval gpo_change=gpo_change-14400\
	| eval gpo_change=strftime(gpo_change, "%F"." "."%T")\
	| eval gpo_creation=strptime(gpo_creation, "%Y-%m-%d %H:%M:%S%Z")\
	| eval gpo_creation=gpo_creation-14400\
	| eval gpo_creation=strftime(gpo_creation, "%F"." "."%T")\
	| eval gpo_domain="jdi"\
	| inputlookup append=true gpo.csv | stats first(*) as * by gpo_id | outputlookup gpo.csv

[User List Main]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 30 0 * * *
dispatch.earliest_time = -24h@d
dispatch.latest_time = now
enableSched = 1
search = | inputlookup user_list_base.csv | eval user_exists=if(strptime(user_date, "%F") >= now()-(60*60*24*2), "1","0") | where user_exists="1" | fields - user_exists |  outputlookup user_list_main.csv

[Asset List Bluecoat update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 21 * * *
dispatch.earliest_time = -180d
dispatch.latest_time = now
enableSched = 1
search = index=main sourcetype="bluecoat:proxysg:access:file" src=*\
	| fields src date cs_username\
	| dedup src\
	| rename src as ip\
	| join ip [|inputlookup asset_list.csv | fields ip host]\
	| rename ip as bluecoat_ip\
	| rename cs_username as bluecoat_user\
	| rename date as bluecoat_date\
	| eval bluecoat=1\
	| fields host bluecoat_ip bluecoat_user bluecoat_date bluecoat\
	| `asset_list_update`\
	| outputlookup asset_list.csv

[User Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 0 * * *
enableSched = 1
search = | ldapsearch search="(objectClass=user)" attrs="cn, company, department, description, displayName, distinguishedName, employeeID, employeeType, givenName, homeDirectory, initials, lastLogonTimestamp, mail, name, objectSid, roomNumber, sAMAccountName, sn, uid, userAccountControl, userPrincipalName, whenChanged, whenCreated" \
	| search cn="*" \
	| table cn, company, department, description, displayName, distinguishedName, employeeID, employeeType, givenName, homeDirectory, initials, lastLogonTimestamp, mail, name, objectSid,roomNumber, sAMAccountName, sn, uid, userAccountControl, userPrincipalName, whenChanged, whenCreated, _time | `user_usr_update` | inputlookup append=true user_list_base.csv | stats first(user*) as user* by user_samx | outputlookup user_list_base.csv

[User Location Main]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 30 0 * * *
disabled = 1
search = | inputlookup append=true user_printer_table.csv | eval user_printer=split(user_printer,";") | mvexpand user_printer | rex field=user_printer max_match=0 "^(?<building>.+?)\_(?<room>\S+)" |  eval location=if(isnull(room), user_room, room)| replace " *" with * in b2 | lookup user_building location OUTPUT b2 | outputlookup user_printer_main.csv

[SCCM List Start]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 22 * * *
description = Updates The SCCM list
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 15
search = `sccm_list_start` | outputlookup sccm_list.csv

[SCCM Patch Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 30 22 * * *
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 10
search = `sccm_patch_update` | inputlookup append=t sccm_list.csv | stats first(*) AS * by sccm_id2 | outputlookup sccm_list.csv

[SCCM List Heartbeat]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 23 * * *
description = Updates SCCM List with heartbeat info
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 15
search = `sccm_list_heartbeat` | outputlookup sccm_list.csv

[Asset List Update SCCM]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 30 23 * * *
dispatch.earliest_time = -d@h
dispatch.latest_time = now
enableSched = 1
schedule_window = 15
search = | inputlookup append=true sccm_list.csv | `asset_list_update` | outputlookup asset_list.csv

[Asset List Update Cisco ISE]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 45 1 * * *
dispatch.earliest_time = -24h
dispatch.latest_time = now
enableSched = 1
search = `asset_list_ise` | `asset_list_update` | outputlookup asset_list.csv

[Asset List OS Class Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 4 * * *
enableSched = 1
search = | inputlookup asset_list.csv \
	| fields host ad_os hbss_platform hbss_os cylance_os solarwinds_os\
	| eval os_class=case(isnull(ad_os) AND isnull(hbss_platform) AND isnull(cylance_os) AND isnull(acas_os) AND isnull(solarwinds_os), "", \
	like(lower(ad_os),"%centos%") OR like(lower(acas_os),"%centos%") OR like(lower(acas_os),"%red hat%"), "server",\
	like(lower(ad_os),"%cisco%") OR like(lower(ad_os),"%netapp%") OR like(lower(ad_os),"%ontap%") OR like(lower(ad_os),"%sgos%"), "network device", \
	!like(lower(solarwinds_os),"%windows%") AND isnotnull(solarwinds_os) AND isnull(ad_os) AND isnull(hbss_platform) AND isnull(cylance_os) AND isnull(acas_os),"network device",\
	like(lower(ad_os),"%server%") OR like(lower(ad_os),"%linux%") OR like(hbss_platform,"%server%") OR (like(lower(cylance_os),"%windows%") AND like(lower(cylance_os),"%server%")) OR like(lower(acas_os),"%server%"), "server", \
	like(lower(ad_os),"%workstation%") OR (like(lower(ad_os),"%windows%") AND !like(lower(ad_os),"%server%")) OR like(hbss_platform,"%workstation%") OR (like(lower(cylance_os),"%windows%") AND !like(lower(cylance_os),"%server%")) OR (like(lower(acas_os),"%windows%") AND !like(lower(acas_os),"%server%")), "workstation")\
	|`asset_list_update`\
	| outputlookup asset_list.csv

[Asset List Solarwinds Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 22 * * *
dispatch.earliest_time = -24h
dispatch.latest_time = now
enableSched = 1
search = `solarwinds_index` sourcetype=solarwinds* SysName=* sourcetype="solarwinds:nodes"\
	| fields IP_Address SysName PhysicalAddress LastSync Vendor\
	| dedup SysName\
	| eval solarwinds_fqdn = lower(SysName), solarwinds=1, _time=strftime(_time,"%F")\
	| rename _time as solarwinds_date LastSync as solarwinds_lastsync PhysicalAddress as solarwinds_mac IP_Address as solarwinds_ip Vendor as solarwinds_os\
	| eval solarwinds_lastsync=strftime(strptime(solarwinds_lastsync,"%Y-%m-%d"),"%F")\
	| fields - _raw SysName LastSync _time\
	| eval solarwinds_fqdn=if(match(solarwinds_fqdn,"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}"),null(),solarwinds_fqdn)\
	| rex field=solarwinds_fqdn "(?<host>[^\.]+)$"\
	| rex field=solarwinds_fqdn "(?<host>[^\.]+)\.(?<solarwinds_domain>.*)"\
	| `asset_list_update`\
	| outputlookup asset_list.csv

[Software List HBSS Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 1 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
enableSched = 1
search = `compliance_index` sourcetype=mcafee:accm\
	| rename ComputerName as host AuditTime as date VendorName as product_vendor ItemName as product_name Version as product_version InstalledAt as install_date\
	| search product_name!="" product_vendor!=""\
	| table host *date product*\
	| sort 0 - date\
	| outputlookup hbss_software_inventory.csv

[Software List SCCM Update]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = 0 0 * * *
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
enableSched = 1
search = `compliance_index` sourcetype=microsoft:sccm:installedsoftware active=1\
	| join resourceid [search `compliance_index` sourcetype=microsoft:sccm | rename ResourceID as resourceid]\
	| rename _time as date Netbios_Name0 as host operatingSystem0 as os operatingSystemVersion0 as os_version\
	| eval date=strftime(date,"%F")\
	| table date host os os_version product* family*\
	| outputlookup sccm_software_inventory.csv

